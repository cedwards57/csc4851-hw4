{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-28T20:00:58.402307Z","iopub.execute_input":"2022-03-28T20:00:58.402649Z","iopub.status.idle":"2022-03-28T20:00:58.432987Z","shell.execute_reply.started":"2022-03-28T20:00:58.402544Z","shell.execute_reply":"2022-03-28T20:00:58.432323Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-03-28T20:00:58.475095Z","iopub.execute_input":"2022-03-28T20:00:58.475288Z","iopub.status.idle":"2022-03-28T20:00:59.136047Z","shell.execute_reply.started":"2022-03-28T20:00:58.475265Z","shell.execute_reply":"2022-03-28T20:00:59.135265Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom catalyst import dl, utils\n\n#supress warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-03-28T20:00:59.137656Z","iopub.execute_input":"2022-03-28T20:00:59.137893Z","iopub.status.idle":"2022-03-28T20:01:04.239642Z","shell.execute_reply.started":"2022-03-28T20:00:59.137867Z","shell.execute_reply":"2022-03-28T20:01:04.238609Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import os\ndirectories = ['../input/csc4851-homework4/birds_400/test',\n                                '../input/csc4851-homework4/birds_400/train',\n                                '../input//csc4851-homework4/birds_400/valid']\n\nfor dir in directories:\n    label = []\n    path = []\n    for dirname, _,filenames in os.walk(dir):\n        for filename in filenames:\n            label.append(os.path.split(dirname)[1])\n            path.append(os.path.join(dirname,filename))\n    if dir == directories[0]:\n        df_test = pd.DataFrame(columns=['path','label'])\n        df_test['path']=path\n        df_test['label']=label\n    elif dir == directories[1]:\n        df_train = pd.DataFrame(columns=['path','label'])\n        df_train['path']=path\n        df_train['label']=label        \n    elif dir == directories[2]:\n        df_valid = pd.DataFrame(columns=['path','label'])\n        df_valid['path']=path\n        df_valid['label']=label\n","metadata":{"execution":{"iopub.status.busy":"2022-03-28T20:01:04.244362Z","iopub.execute_input":"2022-03-28T20:01:04.246894Z","iopub.status.idle":"2022-03-28T20:01:18.404504Z","shell.execute_reply.started":"2022-03-28T20:01:04.246852Z","shell.execute_reply":"2022-03-28T20:01:18.403745Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-28T20:01:18.406830Z","iopub.execute_input":"2022-03-28T20:01:18.407331Z","iopub.status.idle":"2022-03-28T20:01:18.426406Z","shell.execute_reply.started":"2022-03-28T20:01:18.407293Z","shell.execute_reply":"2022-03-28T20:01:18.425532Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Display 20 picture of the dataset with their labels\nfig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\ndf_sample = df_train.sample(15)\ndf_sample.reset_index(drop=True, inplace=True)\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(df_sample.path[i]))\n    ax.set_title(df_sample.label[i])\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-28T20:01:18.434569Z","iopub.execute_input":"2022-03-28T20:01:18.436333Z","iopub.status.idle":"2022-03-28T20:01:19.798386Z","shell.execute_reply.started":"2022-03-28T20:01:18.436298Z","shell.execute_reply":"2022-03-28T20:01:19.797634Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.datasets as dsets\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2022-03-28T20:01:19.799448Z","iopub.execute_input":"2022-03-28T20:01:19.799681Z","iopub.status.idle":"2022-03-28T20:01:19.807613Z","shell.execute_reply.started":"2022-03-28T20:01:19.799651Z","shell.execute_reply":"2022-03-28T20:01:19.806606Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Hyper Parameters \n# input_size = 3*3*64\nnum_classes = 400\n# num_epochs = 5\nbatch_size = 25\nlearning_rate = 0.005","metadata":{"execution":{"iopub.status.busy":"2022-03-28T20:01:19.809473Z","iopub.execute_input":"2022-03-28T20:01:19.809805Z","iopub.status.idle":"2022-03-28T20:01:19.816419Z","shell.execute_reply.started":"2022-03-28T20:01:19.809770Z","shell.execute_reply":"2022-03-28T20:01:19.815607Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"transform_dict = transforms.Compose([transforms.Resize((120, 120)),\n        transforms.RandomResizedCrop(120),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.8],[0.1])\n        ]) #normalize! 0.5? //input_size not same as dimensions // \n\ntrain_data = torchvision.datasets.ImageFolder(root=directories[1], transform=transform_dict)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=4)\n\ntest_data = torchvision.datasets.ImageFolder(root=directories[0], transform=transform_dict)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=4)\n\nvalid_data = torchvision.datasets.ImageFolder(root=directories[2], transform=transform_dict)\nvalid_loader = torch.utils.data.DataLoader(valid_data, batch_size=5, shuffle=False, drop_last=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T20:01:19.818134Z","iopub.execute_input":"2022-03-28T20:01:19.818505Z","iopub.status.idle":"2022-03-28T20:01:20.651601Z","shell.execute_reply.started":"2022-03-28T20:01:19.818472Z","shell.execute_reply":"2022-03-28T20:01:20.650840Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Birdinator(nn.Module): # add model.train, model.eval\n    def __init__(self, num_classes):\n        super(Birdinator, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=5)\n        self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n        self.conv3 = nn.Conv2d(32,64, kernel_size=5)\n        self.pool1 = nn.MaxPool2d(2)\n        self.pool2 = nn.MaxPool2d(2)\n        self.fc1 = nn.Linear(64*6*6, 256)\n        self.fc2 = nn.Linear(256, 400)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = F.relu(self.pool1(x))\n        x = F.relu(F.max_pool2d(self.conv3(x),2))\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = F.relu(self.pool2(x))\n        # print(x.shape)\n\n        x = x.view(-1,64*6*6)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\nmodel = Birdinator(num_classes)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T20:01:20.652725Z","iopub.execute_input":"2022-03-28T20:01:20.652959Z","iopub.status.idle":"2022-03-28T20:01:20.692974Z","shell.execute_reply.started":"2022-03-28T20:01:20.652925Z","shell.execute_reply":"2022-03-28T20:01:20.692334Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()  \noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T20:01:20.695632Z","iopub.execute_input":"2022-03-28T20:01:20.695894Z","iopub.status.idle":"2022-03-28T20:01:20.700827Z","shell.execute_reply.started":"2022-03-28T20:01:20.695850Z","shell.execute_reply":"2022-03-28T20:01:20.699173Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-03-28T20:01:20.702108Z","iopub.execute_input":"2022-03-28T20:01:20.702901Z","iopub.status.idle":"2022-03-28T20:01:20.712358Z","shell.execute_reply.started":"2022-03-28T20:01:20.702862Z","shell.execute_reply":"2022-03-28T20:01:20.711465Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"epochs = 20\nfor epoch in range(epochs):\n\n    running_loss = 0.0\n    model.train()\n    model.cuda()\n    for i, (batch, labels) in enumerate(train_loader):\n        batch = batch.to(torch.device(\"cuda\"))\n        labels = labels.to(torch.device(\"cuda\"))\n        optimizer.zero_grad()\n        y_pred =  model(batch)\n        cel = nn.CrossEntropyLoss()\n        loss = cel(y_pred,labels)\n        loss.backward()\n        optimizer.step()\n      \n        running_loss += loss.item()\n        if i % 500 == 499:    # print every 500 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 500))\n            running_loss = 0.0\n\nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2022-03-28T20:01:20.715449Z","iopub.execute_input":"2022-03-28T20:01:20.715777Z","iopub.status.idle":"2022-03-28T20:44:40.006913Z","shell.execute_reply.started":"2022-03-28T20:01:20.715748Z","shell.execute_reply":"2022-03-28T20:44:40.005916Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\nPATH = \"./save_model\"\ntorch.save(model.state_dict(), PATH)\n\nmodel = Birdinator(num_classes)\n\n# model.load_state_dict(torch.load(PATH))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T20:44:40.008464Z","iopub.execute_input":"2022-03-28T20:44:40.009575Z","iopub.status.idle":"2022-03-28T20:44:40.033659Z","shell.execute_reply.started":"2022-03-28T20:44:40.009510Z","shell.execute_reply":"2022-03-28T20:44:40.033007Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"PATH = \"./save_model\"\nmodel.load_state_dict(torch.load(PATH))\n\ndataiter = iter(test_loader)\nimages, labels = dataiter.next()\n\noutputs = model(images)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T20:44:40.034999Z","iopub.execute_input":"2022-03-28T20:44:40.035253Z","iopub.status.idle":"2022-03-28T20:44:41.135064Z","shell.execute_reply.started":"2022-03-28T20:44:40.035219Z","shell.execute_reply":"2022-03-28T20:44:41.133807Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"correct = 0\ntotal = 0\ncel = nn.CrossEntropyLoss()\nbirds = []\nid = []\n# since we're not training, we don't need to calculate the gradients for our outputs\nwith torch.no_grad():\n    for i, data in enumerate(valid_loader):\n      if i % 100 == 99:\n        print(\"1/4...\")\n      images, labels = data\n      # calculate outputs by running images through the network\n      outputs = model(images)\n      loss = cel(outputs,labels)\n      id.append(i+1)\n      birds.append(loss.item())\n      _, predicted = torch.max(outputs.data, 1)\n      total += labels.size(0)\n      correct += (predicted == labels).sum().item()\n\nprint('Accuracy of this network on validation images: %d %%' % (100 * correct / total))\n","metadata":{"execution":{"iopub.status.busy":"2022-03-28T20:44:41.137468Z","iopub.execute_input":"2022-03-28T20:44:41.137816Z","iopub.status.idle":"2022-03-28T20:45:04.803771Z","shell.execute_reply.started":"2022-03-28T20:44:41.137772Z","shell.execute_reply":"2022-03-28T20:45:04.802131Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"submission_list = np.array([id, birds])\nsubmission_list = np.transpose(submission_list)\nsubmission = pd.DataFrame({'id': id, 'birds': birds})\nsubmission.to_csv('submission.csv', index=False)\nsubmission.tail()","metadata":{"execution":{"iopub.status.busy":"2022-03-28T20:45:04.805636Z","iopub.execute_input":"2022-03-28T20:45:04.805924Z","iopub.status.idle":"2022-03-28T20:45:04.830899Z","shell.execute_reply.started":"2022-03-28T20:45:04.805875Z","shell.execute_reply":"2022-03-28T20:45:04.830217Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":".","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":".\n\n\n\n\n\n\n\n\n\n\n\n.","metadata":{}},{"cell_type":"markdown","source":"\n\n\n\n\n\n\n\n\n\n\n","metadata":{}}]}